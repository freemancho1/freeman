{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from freeman.task.trading.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/freeman/projects/data/trading/data/train_5930.csv\", sep=\",\")\n",
    "test_df = pd.read_csv(\"/home/freeman/projects/data/trading/data/test_5930.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/home/freeman/projects/data/trading/temp/max_value.pkl\", \"rb\") as f:\n",
    "    max_value = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96800.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value[\"high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.iloc[:, :-1].copy(deep=True), train_df.iloc[:, -1:]\n",
    "test_x, test_y = test_df.iloc[:, :-1].copy(deep=True), test_df.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'low', 'high', 'close', 'diff', 'ratio', 'volume',\n",
       "       'value', 't_value', 't_volume', 'year', 'day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2018-05-04\n",
       "1       2018-05-08\n",
       "2       2018-05-09\n",
       "3       2018-05-10\n",
       "4       2018-05-11\n",
       "           ...    \n",
       "1008    2022-06-10\n",
       "1009    2022-06-13\n",
       "1010    2022-06-14\n",
       "1011    2022-06-15\n",
       "1012    2022-06-16\n",
       "Name: date, Length: 1013, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=5)\n",
    "dtr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_pred_y = dtr.predict(test_x.iloc[:, 1:])\n",
    "test_yy = test_y.to_numpy()\n",
    "test_yy = np.squeeze(test_yy, axis=1)\n",
    "test_yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "dtr_mse = mean_squared_error(dtr_pred_y, test_yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004818246594561378, 466.40627035354146)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_mse, dtr_mse*max_value[\"high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31302/158887813.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  etr.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr = ExtraTreesRegressor()\n",
    "etr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_pred_y = etr.predict(test_x.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005083387549777849, 492.07191481849577)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr_mse = mean_squared_error(etr_pred_y, test_yy)\n",
    "etr_mse, etr_mse*max_value[\"high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m setup_rgs \u001b[39m=\u001b[39m setup(data\u001b[39m=\u001b[39mtrain_x\u001b[39m.\u001b[39mto_numpy(), target\u001b[39m=\u001b[39mtrain_y, session_id\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m top5 \u001b[39m=\u001b[39m compare_models(sort\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMSE\u001b[39m\u001b[39m\"\u001b[39m, n_select\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf27p39/lib/python3.9/site-packages/pycaret/regression.py:573\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(data, target, train_size, test_data, preprocess, imputation_type, iterative_imputation_iters, categorical_features, categorical_imputation, categorical_iterative_imputer, ordinal_features, high_cardinality_features, high_cardinality_method, numeric_features, numeric_imputation, numeric_iterative_imputer, date_features, ignore_features, normalize, normalize_method, transformation, transformation_method, handle_unknown_categorical, unknown_categorical_method, pca, pca_method, pca_components, ignore_low_variance, combine_rare_levels, rare_level_threshold, bin_numeric_features, remove_outliers, outliers_threshold, remove_multicollinearity, multicollinearity_threshold, remove_perfect_collinearity, create_clusters, cluster_iter, polynomial_features, polynomial_degree, trigonometry_features, polynomial_threshold, group_features, group_names, feature_selection, feature_selection_threshold, feature_selection_method, feature_interaction, feature_ratio, interaction_threshold, transform_target, transform_target_method, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, custom_pipeline, html, session_id, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, silent, verbose, profile, profile_kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39m# no more python code should be added before this line\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[0;32m--> 573\u001b[0m     data \u001b[39m=\u001b[39m data()\n\u001b[1;32m    575\u001b[0m available_plots \u001b[39m=\u001b[39m {\n\u001b[1;32m    576\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mparameter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mHyperparameters\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    577\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresiduals\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mResiduals\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresiduals_interactive\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mInteractive Residuals\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    588\u001b[0m }\n\u001b[1;32m    590\u001b[0m \u001b[39mif\u001b[39;00m log_plots \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "setup_rgs = setup(data=train_x.to_numpy(), target=train_y, session_id=10)\n",
    "top5 = compare_models(sort=\"MSE\", n_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omp = create_model('omp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_omp = tune_model(omp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = [tuned_et, tuned_cat, tuned_ada, tuned_rf, tuned_omp, tuned_gbr]\n",
    "blender = blend_models(tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = predict_model(blender_top5, data=test_x)\n",
    "pred_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf27p39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adc6a6ffc7682364230b93b75ca0d1bdd8db84ff27ffd4d90b08b9e56198ae80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
