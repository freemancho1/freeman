{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN\n",
    "\n",
    "Deep Convolutional Generatice Adversarial Network\n",
    "\n",
    "![](https://www.researchgate.net/publication/331282441/figure/fig3/AS:729118295478273@1550846756282/Deep-convolutional-generative-adversarial-networks-DCGAN-for-generative-model-of-BF-NSP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "train_x = train_x / 127.5 - 1\n",
    "train_x = np.expand_dims(train_x, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = train_x.shape\n",
    "DATA_SHAPE = INPUT_SHAPE[1:]\n",
    "DATA_ROWS = DATA_SHAPE[0]\n",
    "DATA_COLS = DATA_SHAPE[1]\n",
    "DATA_CHANNELS = DATA_SHAPE[2]\n",
    "DATA_SIZE = np.prod(DATA_SHAPE)\n",
    "\n",
    "LATENT_Z_DIMS = 100\n",
    "\n",
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 128\n",
    "NUM_DISPLAY_LOG = 20\n",
    "EPOCH_DISPLAY_LOG = EPOCHS // NUM_DISPLAY_LOG\n",
    "\n",
    "REAL_LABELS, FAKE_LABELS = np.ones((BATCH_SIZE, 1)), np.zeros((BATCH_SIZE, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Input: Latent Z data\n",
    "        tf.keras.layers.Dense(units=7*7*128, input_dim=LATENT_Z_DIMS),\n",
    "        tf.keras.layers.Reshape((7,7,128)),\n",
    "        \n",
    "        # DC Conv2D #1\n",
    "        tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(2,2), \n",
    "                                        padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.01),\n",
    "        \n",
    "        # DC Conv2D #2\n",
    "        tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3,3), padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.01),\n",
    "        \n",
    "        # DC Conv2D Last\n",
    "        tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2),\n",
    "                                        padding=\"same\", activation=\"tanh\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Convolutional Layers\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), \n",
    "                               padding=\"same\", input_shape=DATA_SHAPE),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.01),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.01),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.01),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        # Full-Connected Layers\n",
    "        tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dcgan(generator, discriminator):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        generator,\n",
    "        discriminator\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_5 (Sequential)   (None, 28, 28, 1)         726401    \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 1)                 1418753   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,145,154\n",
      "Trainable params: 726,209\n",
      "Non-trainable params: 1,418,945\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "discriminator.trainable = False \n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "dcgan = build_dcgan(generator, discriminator)\n",
    "dcgan.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "dcgan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DCGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_train_data():\n",
    "    real_idx = np.random.randint(0, INPUT_SHAPE[0], BATCH_SIZE)\n",
    "    real_images = train_x[real_idx]\n",
    "    latent_data = np.random.normal(0, 1, (BATCH_SIZE, LATENT_Z_DIMS))\n",
    "    fake_images = generator.predict(latent_data, verbose=0)\n",
    "    \n",
    "    batch_x = np.vstack([real_images, fake_images])\n",
    "    batch_y = np.vstack([REAL_LABELS, FAKE_LABELS])\n",
    "    shuffle_idx = np.arange(batch_x.shape[0])\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    batch_x = batch_x[shuffle_idx]\n",
    "    batch_y = batch_y[shuffle_idx]\n",
    "    return batch_x, batch_y\n",
    "\n",
    "def get_generator_train_data():\n",
    "    return np.random.normal(0, 1, (BATCH_SIZE, LATENT_Z_DIMS)), REAL_LABELS\n",
    "\n",
    "def get_eta(num_curr, time_curr):\n",
    "    return datetime.now() + (NUM_DISPLAY_LOG - num_curr) * time_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    start_train = datetime.now()\n",
    "    print(f\"Start Training - Data Shape: {INPUT_SHAPE}, \"\n",
    "            f\"Epochs: {EPOCHS}, Batch Size: {BATCH_SIZE}, \"\n",
    "            f\"Time: {start_train}\")\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    start_loop = datetime.now()\n",
    "    for epoch in range(EPOCHS):\n",
    "        x, y = get_discriminator_train_data()\n",
    "        d_loss, d_accuracy = discriminator.train_on_batch(x, y)\n",
    "        x, y = get_generator_train_data()\n",
    "        g_loss = dcgan.train_on_batch(x, y)\n",
    "        \n",
    "        if (epoch+1) % EPOCH_DISPLAY_LOG == 0:\n",
    "            losses.append((d_loss, g_loss))\n",
    "            accuracies.append(d_accuracy*100)\n",
    "            \n",
    "            end_loop = datetime.now()\n",
    "            num_curr_loop = (epoch+1) // EPOCH_DISPLAY_LOG\n",
    "            print(f\"{epoch+1: >6}({num_curr_loop: >2}/{NUM_DISPLAY_LOG}), \"\n",
    "                  f\"[D loss: {d_loss:8.5f}, accuracy: {d_accuracy:8.5f}], \"\n",
    "                  f\"[G loss: {g_loss:8.5f}], \"\n",
    "                  f\"Time[(Curr){end_loop-start_loop}, (Total){end_loop-start_train}, \"\n",
    "                  f\"(ETA){get_eta(num_curr_loop, end_loop-start_loop)}]\")\n",
    "            start_loop = end_loop\n",
    "            \n",
    "    end_train = datetime.now()\n",
    "    print(f\"End Training - Time: {end_train}, \"\n",
    "          f\"Total Processing Time: {end_train-start_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training - Data Shape: (60000, 28, 28, 1), Epochs: 10000, Batch Size: 128, Time: 2022-10-07 21:39:29.523741\n",
      "   500( 1/20), [D loss:  0.23503, accuracy:  0.90625], [G loss:  2.88385], Time[(Curr)0:00:27.182249, (Total)0:00:27.182291, (ETA)2022-10-07 21:48:33.168784]\n",
      "  1000( 2/20), [D loss:  0.26363, accuracy:  0.87891], [G loss:  3.16406], Time[(Curr)0:00:26.803939, (Total)0:00:53.986230, (ETA)2022-10-07 21:48:25.980893]\n",
      "  1500( 3/20), [D loss:  0.17858, accuracy:  0.92969], [G loss:  2.72501], Time[(Curr)0:00:27.294675, (Total)0:01:21.280905, (ETA)2022-10-07 21:48:34.814143]\n",
      "  2000( 4/20), [D loss:  0.18563, accuracy:  0.91797], [G loss:  3.75814], Time[(Curr)0:00:28.574728, (Total)0:01:49.855633, (ETA)2022-10-07 21:48:56.575044]\n",
      "  2500( 5/20), [D loss:  0.15983, accuracy:  0.94141], [G loss:  3.93781], Time[(Curr)0:00:27.832500, (Total)0:02:17.688133, (ETA)2022-10-07 21:48:44.699392]\n",
      "  3000( 6/20), [D loss:  0.16827, accuracy:  0.93750], [G loss:  3.53357], Time[(Curr)0:00:27.906103, (Total)0:02:45.594236, (ETA)2022-10-07 21:48:45.803441]\n",
      "  3500( 7/20), [D loss:  0.19364, accuracy:  0.92969], [G loss:  4.00985], Time[(Curr)0:00:26.722644, (Total)0:03:12.316880, (ETA)2022-10-07 21:48:29.235013]\n",
      "  4000( 8/20), [D loss:  0.13816, accuracy:  0.94531], [G loss:  4.20213], Time[(Curr)0:00:26.681561, (Total)0:03:38.998441, (ETA)2022-10-07 21:48:28.700942]\n",
      "  4500( 9/20), [D loss:  0.12045, accuracy:  0.95312], [G loss:  4.07306], Time[(Curr)0:00:27.099619, (Total)0:04:06.098060, (ETA)2022-10-07 21:48:33.717630]\n",
      "  5000(10/20), [D loss:  0.16572, accuracy:  0.91797], [G loss:  4.31902], Time[(Curr)0:00:26.926792, (Total)0:04:33.024852, (ETA)2022-10-07 21:48:31.816532]\n",
      "  5500(11/20), [D loss:  0.13588, accuracy:  0.94922], [G loss:  4.11184], Time[(Curr)0:00:26.864567, (Total)0:04:59.889419, (ETA)2022-10-07 21:48:31.194284]\n",
      "  6000(12/20), [D loss:  0.17308, accuracy:  0.91797], [G loss:  3.84755], Time[(Curr)0:00:27.344051, (Total)0:05:27.233470, (ETA)2022-10-07 21:48:35.509641]\n",
      "  6500(13/20), [D loss:  0.12636, accuracy:  0.94922], [G loss:  4.07183], Time[(Curr)0:00:27.301230, (Total)0:05:54.534700, (ETA)2022-10-07 21:48:35.167073]\n",
      "  7000(14/20), [D loss:  0.13410, accuracy:  0.93750], [G loss:  4.57835], Time[(Curr)0:00:27.155727, (Total)0:06:21.690427, (ETA)2022-10-07 21:48:34.148550]\n",
      "  7500(15/20), [D loss:  0.08650, accuracy:  0.98047], [G loss:  4.82257], Time[(Curr)0:00:27.523206, (Total)0:06:49.213633, (ETA)2022-10-07 21:48:36.353424]\n",
      "  8000(16/20), [D loss:  0.15940, accuracy:  0.94141], [G loss:  5.20889], Time[(Curr)0:00:27.187459, (Total)0:07:16.401092, (ETA)2022-10-07 21:48:34.674691]\n",
      "  8500(17/20), [D loss:  0.13201, accuracy:  0.94531], [G loss:  4.56921], Time[(Curr)0:00:26.946864, (Total)0:07:43.347956, (ETA)2022-10-07 21:48:33.712309]\n",
      "  9000(18/20), [D loss:  0.10254, accuracy:  0.95312], [G loss:  4.69658], Time[(Curr)0:00:27.260455, (Total)0:08:10.608411, (ETA)2022-10-07 21:48:34.653088]\n",
      "  9500(19/20), [D loss:  0.07055, accuracy:  0.97266], [G loss:  5.02296], Time[(Curr)0:00:26.869979, (Total)0:08:37.478390, (ETA)2022-10-07 21:48:33.872137]\n",
      " 10000(20/20), [D loss:  0.12159, accuracy:  0.96094], [G loss:  4.65250], Time[(Curr)0:00:26.344298, (Total)0:09:03.822688, (ETA)2022-10-07 21:48:33.346450]\n",
      "End Training - Time: 2022-10-07 21:48:33.346513, Total Processing Time: 0:09:03.822772\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "* Home PC\n",
    "```log\n",
    "Start Training - Data Shape: (60000, 28, 28, 1), Epochs: 10000, Batch Size: 128, Time: 2022-10-07 21:39:29.523741\n",
    "  9500(19/20), [D loss:  0.07055, accuracy:  0.97266], [G loss:  5.02296], Time[(Curr)0:00:26.869979, (Total)0:08:37.478390, (ETA)2022-10-07 21:48:33.872137]\n",
    " 10000(20/20), [D loss:  0.12159, accuracy:  0.96094], [G loss:  4.65250], Time[(Curr)0:00:26.344298, (Total)0:09:03.822688, (ETA)2022-10-07 21:48:33.346450]\n",
    "End Training - Time: 2022-10-07 21:48:33.346513, Total Processing Time: 0:09:03.822772\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf27p39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adc6a6ffc7682364230b93b75ca0d1bdd8db84ff27ffd4d90b08b9e56198ae80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
