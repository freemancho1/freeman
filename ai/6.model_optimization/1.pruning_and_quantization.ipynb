{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가중치 가지치기 및 양자화를 통한 모델 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "1. MNIST 데이터를 tf.keras 라이브러리를 이용해 모델링한다.\n",
    "2. Pruning API를 적용하여 모델을 미세조정하고 정확도를 확인한다.\n",
    "3. 가지치기에서 3배 더 작은 TF와 TFLite 모델을 만든다.\n",
    "4. 가지치기와 훈련 후 양자화를 거쳐 10배 더 작은 TFLite 모델을 만든다.\n",
    "5. 최적화된 TF 및 TFLite 모델의 정확도를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 로그 제어\n",
    "from freeman.utils.support_tf import LogLevelManager as llm\n",
    "llm.set(2)      # 경고 이상만 출력(DEBUG, INFO 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_DIR = os.path.join(os.path.expanduser(\"~\"), \"temp\")\n",
    "FILE_MODEL_NORMAL = os.path.join(BASE_MODEL_DIR, \"model_normal.h5\")\n",
    "FILE_MODEL_KERAS = os.path.join(BASE_MODEL_DIR, \"model_keras.h5\")\n",
    "FILE_MODEL_TFLITE = os.path.join(BASE_MODEL_DIR, \"model_tflite.tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일반 모델 훈련(with MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화(0~1)\n",
    "train_x, test_x = train_x / 255., test_x / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2028)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20290     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_normal = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(filters=12, kernel_size=(3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_normal.compile(optimizer=\"adam\",\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "model_normal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 11.4 s, total: 1min 28s\n",
      "Wall time: 52.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a54073610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 모델 훈련\n",
    "model_normal.fit(train_x, train_y, epochs=5, validation_split=0.1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "_, accuracy_normal = model_normal.evaluate(test_x, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "tf.keras.models.save_model(model_normal, FILE_MODEL_NORMAL, include_optimizer=False)\n",
    "size_file_normal = os.path.getsize(FILE_MODEL_NORMAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가지치기(Pruning)를 통한 모델 미세조정\n",
    "\n",
    "* 가지치기를 전체 모델에 적용하고 모델 요약에서 이를 확인한다.\n",
    "* 이 예제는 50% 희소성(가중치가 0인 50%)으로 모델을 시작하고, 80% 희소성으로 종료한다.\n",
    "* <b>모델 정확도를 높이기 위해 일부 레이어를 잘라낼 수 도 있다.</b>(이 예제에는 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning 옵션 설정\n",
    "\n",
    "## 여기서 정의된 batch_size, epochs 등은 위에서 학습된 모델에서 사용된 것이 아니라,\n",
    "## 가지치기를 위한 파라미터임.\n",
    "PRUNE_BATCH_SIZE = 128\n",
    "PRUNE_EPOCHS = 5\n",
    "PRUNE_VALIDATION_SPLIT = 0.1\n",
    "\n",
    "PRUNE_TRAIN_DATA_SIZE = train_x.shape[0] * (1 - PRUNE_VALIDATION_SPLIT)\n",
    "PRUNE_END_STEP = np.ceil(PRUNE_TRAIN_DATA_SIZE/PRUNE_BATCH_SIZE).astype(np.int32) * PRUNE_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "    \"pruning_schedule\":\n",
    "        tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.50,\n",
    "            final_sparsity=0.80,\n",
    "            begin_step=0,\n",
    "            end_step=PRUNE_END_STEP\n",
    "        ),\n",
    "}\n",
    "\n",
    "# 일반 모델에 가지치기를 한 모델 정의\n",
    "model_keras = tfmot.sparsity.keras.prune_low_magnitude(model_normal, **pruning_params)\n",
    "# 가지치기 모델 컴파일(일반 모델과 동일(컴파일/훈련/평가)하게 처리됨)\n",
    "model_keras.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.3 s, sys: 7.71 s, total: 50.1 s\n",
      "Wall time: 20.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a52fd38b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "# 가지치기 모델 훈련용 콜백함수 정의\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),               # 훈련중 사용\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),  # 진행사항 추적 및 디버깅용 로그 제공\n",
    "]\n",
    "\n",
    "# 가지치기 모델 훈련\n",
    "model_keras.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=PRUNE_BATCH_SIZE,\n",
    "    epochs=PRUNE_EPOCHS,\n",
    "    validation_split=PRUNE_VALIDATION_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.10.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy_keras = model_keras.evaluate(test_x, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model_keras, FILE_MODEL_KERAS, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일반 및 가지치기 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2028)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20290     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_normal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d   (None, 26, 26, 12)       230       \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 13, 13, 12)       1         \n",
      " ling2d (PruneLowMagnitude)                                      \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 2028)             1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense (  (None, 10)               40572     \n",
      " PruneLowMagnitude)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 압축 가능한 모델로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5xo4b3wd/assets\n"
     ]
    }
   ],
   "source": [
    "# 학습 완료된 가지치기 모델을 압축 가능한 모델로 변경\n",
    "model_keras_before_zip = tfmot.sparsity.keras.strip_pruning(model_keras)\n",
    "\n",
    "# 압축 가능한 모델을 이용해 TFLite 모델로 생성\n",
    "tflite_converter = tf.lite.TFLiteConverter.from_keras_model(model_keras_before_zip)\n",
    "model_tflite_before_zip = tflite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 압축 가능한 모델 저장\n",
    "_, temp_keras_file = tempfile.mkstemp(\".h5\")\n",
    "_, temp_tflite_file = tempfile.mkstemp(\".tflite\")\n",
    "\n",
    "tf.keras.models.save_model(model_keras_before_zip, temp_keras_file, include_optimizer=False)\n",
    "with open(temp_tflite_file, \"wb\") as f:\n",
    "    f.write(model_tflite_before_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 압축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 압축함수 정의\n",
    "def gzipped_model(file):\n",
    "    _, zipped_file = tempfile.mkstemp(\".zip\")\n",
    "    with zipfile.ZipFile(zipped_file, \"w\", compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_file_keras = os.path.getsize(FILE_MODEL_KERAS)\n",
    "size_file_keras_zip = gzipped_model(temp_keras_file)\n",
    "size_file_tflite = os.path.getsize(temp_tflite_file)\n",
    "size_file_tflite_zip = gzipped_model(temp_tflite_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가지치기와 양자화를 결합해 10배 더 작은 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvpwir19a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvpwir19a/assets\n"
     ]
    }
   ],
   "source": [
    "tflite_converter = tf.lite.TFLiteConverter.from_keras_model(model_keras_before_zip)\n",
    "tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "model_quantized = tflite_converter.convert()\n",
    "\n",
    "_, temp_quantized_file = tempfile.mkstemp(\".tflite\")\n",
    "with open(temp_quantized_file, \"wb\") as f:\n",
    "    f.write(model_quantized)\n",
    "    \n",
    "size_file_quantized = os.path.getsize(temp_quantized_file)\n",
    "size_file_quantized_zip = gzipped_model(temp_quantized_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 압축파일 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    \n",
    "    prediction_digits = []\n",
    "    for i, test_data in enumerate(test_x):\n",
    "        if i % 2000 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "        test_data = np.expand_dims(test_data, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "    print()\n",
    "    \n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_y).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=model_quantized)\n",
    "interpreter.allocate_tensors()\n",
    "accuracy_tflite = evaluate_model(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf27p39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adc6a6ffc7682364230b93b75ca0d1bdd8db84ff27ffd4d90b08b9e56198ae80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
