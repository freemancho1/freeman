{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.support_tf import LogLevelManager as llm\n",
    "llm.set(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = np.array([[1.5, 2., 0], [8, 2., 6.]])  # (2,3)\n",
    "temp_output = tf.keras.layers.Embedding(\n",
    "    # 입력값중 가장 큰 수+1,\n",
    "    # 임베딩이 주로 단어처리 시 사용하기 때문에 사전의 크기와 추가된 특수문자(PAD,UNK 등))가\n",
    "    # 모두 일련번호로 되어 있어 대부분 설명이 단어집합의 크기라고 하지만,\n",
    "    # (다시 말하면 0부터 시작하는 일련번호이기 때문에 가장 큰 수가 단어집합의 크기)\n",
    "    # 정확하게는 입력값중 가장 큰 수가 맞을 듯\n",
    "    # 아래와 같이 7을 입력하면, 위에 있는 8은 임베딩되지 않음.\n",
    "    input_dim=7, \n",
    "    # 각 숫자를 몇 차원으로 의미있게 만들지 정함\n",
    "    output_dim=4, \n",
    "    # 각 입력 데이터의 길이(지정하지 않아도 됨)\n",
    "    input_length=len(temp_input[0]),\n",
    "    # 기본값은 'False'이며, 'True'로 처리하면,\n",
    "    # <PAD>값(= 보통 0)을 임베딩은 하지만, \n",
    "    # 패딩 데이터라고 지정해 모델링에서 사용하지 않도록 지정함(아래 참조).\n",
    "    mask_zero=True)(temp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[-0.023783  , -0.02757638,  0.03147807, -0.04107536],\n",
       "        [-0.02517281,  0.04083048,  0.01646448, -0.01874264],\n",
       "        [-0.0452969 ,  0.03383848,  0.03071577,  0.02956183]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.02517281,  0.04083048,  0.01646448, -0.01874264],\n",
       "        [ 0.04191061, -0.04902036,  0.04034099, -0.04398514]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=bool, numpy=\n",
       "array([[ True,  True, False],\n",
       "       [ True,  True,  True]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf27p39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adc6a6ffc7682364230b93b75ca0d1bdd8db84ff27ffd4d90b08b9e56198ae80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
